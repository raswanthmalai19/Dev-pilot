"""
Config Generator Agent - Gemini-powered configuration generation.

Generates missing configuration files using AI reasoning:
- Dockerfile
- .dockerignore
- Cloud Run configuration
- Environment variables detection
- Port and start command detection
"""

from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List

from .base_agent import BaseAgent
from ..models.project import ProjectInfo, ProjectType, Framework
from ..core.gemini_client import GeminiClient
from ..core.logger import get_logger


@dataclass
class GeneratedConfig:
    """A generated configuration file."""
    filename: str
    content: str
    description: str
    generated_at: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "filename": self.filename,
            "content": self.content,
            "description": self.description,
            "generated_at": self.generated_at.isoformat(),
        }


@dataclass
class RuntimeConfig:
    """Detected runtime configuration."""
    port: int = 8080
    start_command: Optional[str] = None
    health_check_path: str = "/health"
    env_vars: Dict[str, str] = field(default_factory=dict)
    required_env_vars: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "port": self.port,
            "start_command": self.start_command,
            "health_check_path": self.health_check_path,
            "env_vars": self.env_vars,
            "required_env_vars": self.required_env_vars,
        }


@dataclass
class ConfigGeneratorResult:
    """Result of config generation."""
    success: bool
    configs: List[GeneratedConfig] = field(default_factory=list)
    runtime_config: Optional[RuntimeConfig] = None
    dockerfile_path: Optional[str] = None
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "success": self.success,
            "configs": [c.to_dict() for c in self.configs],
            "runtime_config": self.runtime_config.to_dict() if self.runtime_config else None,
            "dockerfile_path": self.dockerfile_path,
            "errors": self.errors,
            "warnings": self.warnings,
        }


# Default templates for common project types
DOCKERFILE_TEMPLATES = {
    ProjectType.PYTHON: '''# Python Dockerfile - Auto-generated by Dev Pilot
FROM python:3.11-slim as builder

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Production stage
FROM python:3.11-slim

WORKDIR /app

# Copy installed packages
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application
COPY . .

# Set environment
ENV PYTHONUNBUFFERED=1
ENV PORT={port}

EXPOSE {port}

CMD {start_command}
''',
    ProjectType.NODEJS: '''# Node.js Dockerfile - Auto-generated by Dev Pilot
FROM node:20-alpine as builder

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci --only=production

# Production stage
FROM node:20-alpine

WORKDIR /app

# Copy node_modules from builder
COPY --from=builder /app/node_modules ./node_modules

# Copy application
COPY . .

ENV NODE_ENV=production
ENV PORT={port}

EXPOSE {port}

CMD {start_command}
''',
    ProjectType.GO: '''# Go Dockerfile - Auto-generated by Dev Pilot
FROM golang:1.21-alpine as builder

WORKDIR /app

# Download dependencies
COPY go.mod go.sum ./
RUN go mod download

# Build
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o main .

# Production stage
FROM alpine:latest

WORKDIR /app

COPY --from=builder /app/main .

ENV PORT={port}

EXPOSE {port}

CMD ["./main"]
''',
}

DOCKERIGNORE_TEMPLATE = '''# Auto-generated by Dev Pilot
.git
.gitignore
README.md
LICENSE
*.md

# Python
__pycache__
*.pyc
*.pyo
.pytest_cache
.coverage
.venv
venv
env

# Node.js
node_modules
npm-debug.log

# IDE
.idea
.vscode
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Docker
Dockerfile
.dockerignore
docker-compose*.yml

# CI/CD
.github
.gitlab-ci.yml

# Terraform
terraform
*.tfstate
*.tfvars
'''


class ConfigGenerator(BaseAgent):
    """
    Gemini-powered configuration generator.
    
    Analyzes project structure and generates missing configuration files
    required for containerization and deployment.
    
    Usage:
        generator = ConfigGenerator()
        result = await generator.run(project_info)
        
        if result.success:
            for config in result.configs:
                print(f"Generated: {config.filename}")
    """
    
    def __init__(
        self,
        working_dir: Path = None,
        gemini_client: GeminiClient = None,
        write_files: bool = True,
    ):
        """
        Initialize the config generator.
        
        Args:
            working_dir: Working directory
            gemini_client: Gemini client for AI generation
            write_files: Whether to write generated files to disk
        """
        super().__init__(working_dir, gemini_client)
        self.write_files = write_files
        self.logger = get_logger("ConfigGenerator")
        
    def _get_system_instruction(self) -> str:
        """Get system instruction for the agent."""
        return """You are an expert DevOps engineer specializing in containerization and cloud deployment.
        
Your task is to analyze project structures and generate optimal configurations for:
- Dockerfiles (multi-stage, optimized for production)
- Docker ignore files
- Cloud Run configurations
- Runtime settings (port, start command, environment variables)

Always follow these best practices:
1. Use multi-stage builds for smaller images
2. Use specific version tags, not 'latest'
3. Run as non-root user when possible
4. Minimize layers
5. Order commands to maximize cache usage
6. Include health check endpoints
7. Set appropriate resource limits"""
    
    async def run(
        self,
        project_info: ProjectInfo,
        force_regenerate: bool = False,
    ) -> ConfigGeneratorResult:
        """
        Generate missing configuration files for a project.
        
        Args:
            project_info: Analyzed project information
            force_regenerate: Regenerate even if files exist
            
        Returns:
            ConfigGeneratorResult with generated configs
        """
        result = ConfigGeneratorResult(success=True)
        
        self.logger.info(f"Generating configs for: {project_info.name}")
        self.logger.info(f"Project type: {project_info.project_type.value}")
        self.logger.info(f"Framework: {project_info.framework.value}")
        
        # 1. Detect runtime configuration
        result.runtime_config = await self._detect_runtime_config(project_info)
        self.logger.info(f"Detected port: {result.runtime_config.port}")
        self.logger.info(f"Start command: {result.runtime_config.start_command}")
        
        # 2. Generate Dockerfile if missing
        dockerfile_path = project_info.path / "Dockerfile"
        if not dockerfile_path.exists() or force_regenerate:
            dockerfile = await self._generate_dockerfile(project_info, result.runtime_config)
            if dockerfile:
                result.configs.append(dockerfile)
                result.dockerfile_path = str(dockerfile_path)
                
                if self.write_files:
                    dockerfile_path.write_text(dockerfile.content)
                    self.logger.info(f"Written: {dockerfile_path}")
        else:
            result.dockerfile_path = str(dockerfile_path)
            result.warnings.append("Dockerfile already exists, skipping generation")
            self.logger.info("Dockerfile already exists")
            
        # 3. Generate .dockerignore if missing
        dockerignore_path = project_info.path / ".dockerignore"
        if not dockerignore_path.exists() or force_regenerate:
            dockerignore = self._generate_dockerignore(project_info)
            result.configs.append(dockerignore)
            
            if self.write_files:
                dockerignore_path.write_text(dockerignore.content)
                self.logger.info(f"Written: {dockerignore_path}")
        else:
            result.warnings.append(".dockerignore already exists, skipping generation")
            
        # 4. Detect environment variables
        env_vars = await self._detect_env_vars(project_info)
        result.runtime_config.required_env_vars = env_vars
        if env_vars:
            self.logger.info(f"Detected env vars: {env_vars}")
        
        self.logger.info(f"Generated {len(result.configs)} config files")
        return result
    
    async def _detect_runtime_config(
        self,
        project_info: ProjectInfo,
    ) -> RuntimeConfig:
        """Detect runtime configuration from project."""
        config = RuntimeConfig()
        
        # Use existing project info if available
        if project_info.port:
            config.port = project_info.port
        if project_info.start_command:
            config.start_command = project_info.start_command
        if project_info.health_endpoint:
            config.health_check_path = project_info.health_endpoint
            
        # Detect from project type
        if not config.start_command:
            config.start_command = self._get_default_start_command(project_info)
            
        # Use Gemini for more accurate detection if available
        if self.gemini and not project_info.start_command:
            try:
                detected = await self._detect_with_gemini(project_info)
                if detected.get("port"):
                    config.port = detected["port"]
                if detected.get("start_command"):
                    config.start_command = detected["start_command"]
                if detected.get("health_path"):
                    config.health_check_path = detected["health_path"]
            except Exception as e:
                self.logger.warning(f"Gemini detection failed: {e}")
                
        return config
    
    def _get_default_start_command(self, project_info: ProjectInfo) -> str:
        """Get default start command based on project type and framework."""
        if project_info.project_type == ProjectType.PYTHON:
            if project_info.framework == Framework.FLASK:
                main_file = project_info.main_file or "app.py"
                return f'["python", "{main_file}"]'
            elif project_info.framework == Framework.FASTAPI:
                return '["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]'
            elif project_info.framework == Framework.DJANGO:
                return '["gunicorn", "--bind", "0.0.0.0:8080", "config.wsgi:application"]'
            elif project_info.framework == Framework.STREAMLIT:
                return '["streamlit", "run", "app.py", "--server.port", "8080", "--server.address", "0.0.0.0"]'
            else:
                main_file = project_info.main_file or "main.py"
                return f'["python", "{main_file}"]'
                
        elif project_info.project_type == ProjectType.NODEJS:
            if project_info.framework in [Framework.NEXTJS]:
                return '["npm", "start"]'
            else:
                return '["node", "index.js"]'
                
        elif project_info.project_type == ProjectType.GO:
            return '["./main"]'
            
        elif project_info.project_type == ProjectType.JAVA:
            return '["java", "-jar", "app.jar"]'
            
        elif project_info.project_type == ProjectType.RUST:
            return '["./app"]'
            
        return '["./start.sh"]'
    
    async def _detect_with_gemini(
        self,
        project_info: ProjectInfo,
    ) -> Dict[str, Any]:
        """Use Gemini to detect runtime configuration."""
        # Read key files for context
        key_files = []
        
        # Check common entry point files
        entry_point_files = [
            "main.py", "app.py", "server.py", "index.js", "server.js",
            "main.go", "cmd/main.go", "src/main.rs",
        ]
        
        for filename in entry_point_files:
            filepath = project_info.path / filename
            if filepath.exists():
                try:
                    content = filepath.read_text()[:2000]  # First 2000 chars
                    key_files.append(f"=== {filename} ===\n{content}")
                except Exception:
                    pass
                    
        if not key_files:
            return {}
            
        prompt = f"""Analyze this {project_info.project_type.value} project and detect:
1. Port number (look for PORT env var or hardcoded port)
2. Start command (how to run the application)
3. Health check endpoint (common: /health, /healthz, /api/health)

Project files:
{chr(10).join(key_files[:3])}

Respond in JSON format:
{{"port": 8080, "start_command": "python app.py", "health_path": "/health"}}

Only respond with valid JSON, no explanation."""

        try:
            response = await self.gemini.generate(prompt, enable_tools=False)
            
            # Parse JSON response
            import json
            # Extract JSON from response
            response_text = response.strip()
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]
            
            return json.loads(response_text)
        except Exception as e:
            self.logger.warning(f"Failed to parse Gemini response: {e}")
            return {}
    
    async def _generate_dockerfile(
        self,
        project_info: ProjectInfo,
        runtime_config: RuntimeConfig,
    ) -> Optional[GeneratedConfig]:
        """Generate Dockerfile for the project."""
        
        # Try to use Gemini for custom generation
        if self.gemini:
            try:
                dockerfile = await self._generate_dockerfile_with_gemini(
                    project_info, runtime_config
                )
                if dockerfile:
                    return dockerfile
            except Exception as e:
                self.logger.warning(f"Gemini Dockerfile generation failed: {e}")
        
        # Fall back to template
        template = DOCKERFILE_TEMPLATES.get(project_info.project_type)
        
        if template:
            content = template.format(
                port=runtime_config.port,
                start_command=runtime_config.start_command or '["./start.sh"]',
            )
            
            return GeneratedConfig(
                filename="Dockerfile",
                content=content,
                description=f"Auto-generated Dockerfile for {project_info.project_type.value} project",
            )
            
        return None
    
    async def _generate_dockerfile_with_gemini(
        self,
        project_info: ProjectInfo,
        runtime_config: RuntimeConfig,
    ) -> Optional[GeneratedConfig]:
        """Generate Dockerfile using Gemini AI."""
        
        # Build context
        deps_info = ""
        if project_info.project_type == ProjectType.PYTHON:
            req_file = project_info.path / "requirements.txt"
            if req_file.exists():
                deps_info = f"requirements.txt:\n{req_file.read_text()[:1000]}"
        elif project_info.project_type == ProjectType.NODEJS:
            pkg_file = project_info.path / "package.json"
            if pkg_file.exists():
                deps_info = f"package.json:\n{pkg_file.read_text()[:1000]}"
                
        prompt = f"""Generate an optimized, production-ready, multi-stage Dockerfile for this project:

Project Type: {project_info.project_type.value}
Framework: {project_info.framework.value}
Port: {runtime_config.port}
Start Command: {runtime_config.start_command}

{deps_info}

Requirements:
1. Use multi-stage build
2. Use specific version tags (not 'latest')
3. Minimize image size
4. Run as non-root user if possible
5. Include proper EXPOSE and CMD
6. Optimize layer caching

Respond with ONLY the Dockerfile content, no explanations or markdown."""

        response = await self.gemini.generate(prompt, enable_tools=False)
        
        # Clean up response
        content = response.strip()
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("dockerfile"):
                content = content[10:]
            content = content.strip()
            
        if content and "FROM" in content:
            return GeneratedConfig(
                filename="Dockerfile",
                content=content,
                description=f"AI-generated Dockerfile for {project_info.project_type.value} project",
            )
            
        return None
    
    def _generate_dockerignore(
        self,
        project_info: ProjectInfo,
    ) -> GeneratedConfig:
        """Generate .dockerignore file."""
        return GeneratedConfig(
            filename=".dockerignore",
            content=DOCKERIGNORE_TEMPLATE,
            description="Docker ignore file to exclude unnecessary files from build context",
        )
    
    async def _detect_env_vars(
        self,
        project_info: ProjectInfo,
    ) -> List[str]:
        """Detect required environment variables."""
        env_vars = []
        
        # Check for .env.example or .env.sample
        for env_file in [".env.example", ".env.sample", ".env.template"]:
            env_path = project_info.path / env_file
            if env_path.exists():
                try:
                    content = env_path.read_text()
                    for line in content.split("\n"):
                        line = line.strip()
                        if line and not line.startswith("#") and "=" in line:
                            var_name = line.split("=")[0].strip()
                            if var_name:
                                env_vars.append(var_name)
                except Exception:
                    pass
                    
        # Add from project info
        env_vars.extend(project_info.required_env_vars)
        
        return list(set(env_vars))
    
    def check_prerequisites(self) -> Dict[str, Any]:
        """Check prerequisites for the generator."""
        return {
            "gemini_available": self.gemini is not None,
            "write_files": self.write_files,
            "ready": True,
        }


# Convenience function
async def generate_configs(
    project_path: Path,
    project_info: ProjectInfo = None,
) -> ConfigGeneratorResult:
    """
    Generate configs for a project.
    
    Args:
        project_path: Path to the project
        project_info: Optional pre-analyzed project info
        
    Returns:
        ConfigGeneratorResult with generated configs
    """
    generator = ConfigGenerator()
    
    if not project_info:
        from .project_analyzer import ProjectAnalyzer
        analyzer = ProjectAnalyzer()
        project_info = await analyzer.run(project_path)
        
    return await generator.run(project_info)
